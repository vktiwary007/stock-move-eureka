{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stockMovement0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOzQzjnyU1efObBbck9e//s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vktiwary007/stock-move-eureka/blob/main/stockMovement0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt_cE5Bm2HTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f20796a-5ead-40da-f8e8-4cd23932cadd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.4.1\n",
            "Eager mode:  True\n",
            "Hub version:  0.11.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhtkn5qPHLTA"
      },
      "source": [
        "import io\n",
        "df = pd.read_csv('Apple240.csv', skiprows=0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "4Qhd_OSJH9TD",
        "outputId": "a89e5fb7-5063-4e24-a179-f61e91b0d236"
      },
      "source": [
        "df[:10]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>News</th>\n",
              "      <th>Movement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>Bearish Calls Lumentum (NASDAQ: LITE ): It's a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>The areas to be concerned are that there are f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>Amazon will soon resume selling the Apple TV (...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>Facing questions from tech analysts, Apple (NA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>Cramer and the AAP team say investors need to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>One day after Apple acknowledged that it has b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>1 . -- U.S. stock futures turned lower on Tues...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>Meanwhile, eight more lawsuits have been filed...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>Shares in Apple and several of its suppliers f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>1 . -- U.S. stock futures traded slightly high...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Source  ... Movement\n",
              "0   seekingalpha.com  ...        1\n",
              "1   seekingalpha.com  ...        1\n",
              "2   seekingalpha.com  ...        1\n",
              "3   seekingalpha.com  ...        0\n",
              "4  www.thestreet.com  ...        0\n",
              "5   seekingalpha.com  ...        1\n",
              "6  www.thestreet.com  ...        1\n",
              "7   seekingalpha.com  ...        1\n",
              "8   seekingalpha.com  ...        1\n",
              "9  www.thestreet.com  ...        0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip8UlgczIB6G"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['News'].values, df.iloc[:, -1].values, test_size = 0.2, random_state = 0)\n",
        "\n",
        "train_examples, train_labels = np.asarray(X_train), np.asarray(y_train)\n",
        "test_examples, test_labels = np.asarray(X_test), np.asarray(y_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "255ApnrVNQ_0",
        "outputId": "cccce60f-6a12-451b-cb38-99dc5c55fdca"
      },
      "source": [
        "train_examples[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Q1 ’16: -4.1%, -6.1% Source: Refinitiv IBES consensus estimates as of 10/22/18 Summary/conclusion: S&P 500 earnings growth is expected to slow to 10% in calendar 2019, and the numbers have been telling investors that for quite some time, as this blog discussed here . I don’t think this is the reason behind this market downdraft that started on October 1 ’18, but we’ll see. China is a growing issue – their growth has slowed and that has to come home to roost in US earnings at some point if it hasn’t already. Companies give some idea of next year’s guidance starting with the 3rd quarter earnings reports every year, but the real or hard guidance occurs with the January-February conference calls that contain 4th quarter results. If we average the above 2019 results, the Tech sector – over the 4 quarters – is expected to average 8.2% EPS growth and 5% revenue growth, inline with the S&P 500’s expected average of 9% EPS growth and 5% revenue growth. As we lap the corporate income tax rate reduction of 2018, the 2019 comps will be tougher, and the S&P 500 will show slower growth, which we’ve known for months. Technology looks to be expecting slower growth as well, but is inline with the S&P 500. However, much depends on Apple’s (NASDAQ: AAPL ) results next week, with their fiscal Q4 ’18 results. Tech has just finished a 6-quarter or 18-month growth cycle, coming out of 2015 and 2016. I worry more about the inevitable rotation from Growth and Momentum. That will likely depress Tech multiples and set readers up for an opportunity to overweight Tech. Clients’ Tech weighting was reduced this summer to roughly 18%-22% (and account weights can vary), which was a little early, but looks better now. After the creation of the Communications sectors, Technology’s market cap weighting within the S&P 500 fell to 20%. Thanks for reading.',\n",
              "       'Highlighting the potential for significant growth to its service business, JPMorgan analyst Samik Chatterjee initiated coverage of Apple Inc. ( AAPL-Q ) with an “overweight” rating.',\n",
              "       'Apple ( AAPL +1.1% ) is talking with at least three private Medicare plans to about getting the Apple Watch to at-risk seniors, according to CNBC sources .',\n",
              "       'Apple: Survey Says People Want Cheaper, Bigger iPhone, Says Piper By Tiernan Ray Mar 5, 2018, 9:13 am 34 pts Rumors of Apple’s (AAPL) 2018 lineup of iPhones are good news, writes Piper Jaffray’s Michael Olson this morning. He describes responses from his survey of iPhone users, showing price and the size of the screen are the big issues holding back people from upgrading. Olson, who has an…',\n",
              "       'Increasing traffic acquisition costs (TAC) paid to companies like Apple ( AAPL ) are being more than offset by operating leverage, after accounting for investments in growth. And the acceleration in earnings growth is likely to continue as TAC growth moderates in the coming quarters, according to management commentary .',\n",
              "       'The twist? You’re not talking to Alexa, or Siri, from Apple Inc. (NASDAQ: AAPL ). You’re not even talking to Watson, as far as you can tell. You’re talking to each organization’s unique version of Watson, taught to do what that company needs done.',\n",
              "       'Investors sentiment increased to 0.7 in 2017 Q3. Its up 0.02, from 0.68 in 2017Q2. It improved, as 52 investors sold AAPL shares while 1034 reduced holdings. 116 funds opened positions while 640 raised stakes. 2.97 billion shares or 2.78% less from 3.06 billion shares in 2017Q2 were reported. Pettee Invsts stated it has 15,440 shares. Stock Yards State Bank & reported 2.99% in Apple Inc. (NASDAQ:AAPL). Factory Mutual has 1.91M shares. Destination Wealth invested in 293,868 shares or 2.89% of the stock. Moreover, Riggs Asset Managment Inc has 2.49% invested in Apple Inc. (NASDAQ:AAPL) for 35,827 shares. 3,330 were accumulated by Schwartz Invest Counsel. Burke & Herbert Bancorp & Tru Comm holds 2.63% or 18,851 shares in its portfolio. The United Kingdom-based Investec Asset Management has invested 0.76% in Apple Inc. (NASDAQ:AAPL). 4,521 were reported by First Bank & Trust Sioux Falls. Hills National Bank Trust Com, a Iowa-based fund reported 41,860 shares. Glg Prns LP holds 10,042 shares. Criterion Capital Management Limited Liability Corp has invested 0.74% of its portfolio in Apple Inc. (NASDAQ:AAPL). The New York-based Engineers Gate Manager LP has invested 0.04% in Apple Inc. (NASDAQ:AAPL). 1,739 were reported by Boyar Asset. Cincinnati Ins holds 0.71% in Apple Inc. (NASDAQ:AAPL) or 154,000 shares. ',\n",
              "       \"Given that AAPL has a Zacks Rank #3 and an ESP in positive territory, investors might want to consider this stock ahead of earnings. You can see the complete list of today's Zacks #1 Rank (Strong Buy) stocks here . \",\n",
              "       'Last year, smart speaker sales went through the roof during the holidays. However, Apple (NASDAQ: AAPL ) missed out on the boost altogether, when its HomePod was delayed. With this year’s holiday shopping season entering the final stretch, Apple is employing a rare tactic in an attempt to gain momentum: emailing HomePod discount codes to Apple Music subscribers.',\n",
              "       \"Want to see what other hedge funds are holding AAPL? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for Apple Inc. (NASDAQ:AAPL). Receive News & Ratings for Apple analysts' ratings for Apple and related companies daily email newsletter . «\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtEGldN0Nagp",
        "outputId": "f9f5f41a-cede-4c32-f770-eb19a1b647d8"
      },
      "source": [
        "train_labels[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 1, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXVtTbcQOnYr",
        "outputId": "e853055f-77a5-4010-8d08-b2619aa0bef7"
      },
      "source": [
        "print(\"Training entries: {}, test entries: {}\".format(len(train_examples), len(test_examples)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 29251, test entries: 7313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMgIvoyrNiTA",
        "outputId": "2d117e69-1161-442a-b8e2-95c2bc5e6c9e"
      },
      "source": [
        "model = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
        "hub_layer = hub.KerasLayer(model, input_shape=[], dtype=tf.string, trainable=True)\n",
        "hub_layer(train_examples[:3])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 50), dtype=float32, numpy=\n",
              "array([[ 1.2355471 ,  0.11719096, -0.19826788,  0.62281877, -0.49590316,\n",
              "        -0.738948  ,  0.7471023 ,  0.61302024, -0.501993  ,  0.2771705 ,\n",
              "         0.07472976,  0.25415528,  0.35520852, -0.36702234,  0.62300056,\n",
              "        -0.7748881 , -0.56931186,  0.45307308,  0.5203001 , -0.03229528,\n",
              "        -0.09448511, -0.35797906,  0.9466501 , -0.08701267,  0.12805209,\n",
              "         0.23130086, -0.6522287 ,  0.44974676, -0.20601137, -0.37608024,\n",
              "         0.21680853, -0.1402651 ,  0.773747  , -0.58659416, -0.07478948,\n",
              "        -0.08432465,  0.37597057, -0.5652265 ,  0.03625645, -0.664764  ,\n",
              "        -0.5988652 ,  0.03650454,  0.3608431 ,  0.5561065 , -0.47489214,\n",
              "        -0.78675216, -0.35815898, -0.03418034, -0.09439875,  0.2157843 ],\n",
              "       [ 0.20898803, -0.37149653,  0.1520238 ,  0.07758274,  0.06931368,\n",
              "        -0.05553383, -0.02514357,  0.19448043, -0.05831357, -0.20240895,\n",
              "        -0.28871888,  0.04763449,  0.11879189, -0.27784148,  0.5745588 ,\n",
              "         0.02003175, -0.1034577 ,  0.2906643 ,  0.00982231,  0.0480089 ,\n",
              "        -0.05520256, -0.28449568,  0.17477784, -0.23907796, -0.11831628,\n",
              "        -0.03490403,  0.01137603,  0.23219433, -0.13676652,  0.01163242,\n",
              "         0.15685223, -0.0347483 , -0.05929662, -0.09887181, -0.05074861,\n",
              "        -0.1335763 ,  0.31326506, -0.17570776, -0.03336982,  0.11695226,\n",
              "        -0.10018534, -0.13103545,  0.03787977,  0.29210827, -0.03673378,\n",
              "        -0.3892708 ,  0.1345425 , -0.03735431, -0.0493186 ,  0.17875238],\n",
              "       [ 0.05457494,  0.0303298 , -0.12102827,  0.26758152,  0.09199125,\n",
              "         0.10085252,  0.06397009, -0.11483375,  0.14231266, -0.03171711,\n",
              "        -0.12512861,  0.16480108, -0.0893893 , -0.19078138,  0.04061276,\n",
              "         0.10066611, -0.19112413,  0.29602993,  0.21310265,  0.16231702,\n",
              "         0.12178949, -0.11619021,  0.13097899, -0.08877624, -0.254493  ,\n",
              "         0.03647542, -0.15634403,  0.07700951, -0.04293624,  0.14340451,\n",
              "         0.02243923, -0.09005149,  0.20288457, -0.23973471, -0.14015701,\n",
              "        -0.11732321, -0.09656764, -0.04261828,  0.08668074,  0.13635187,\n",
              "        -0.0079848 , -0.13173303,  0.20426852,  0.18298975, -0.41210204,\n",
              "        -0.3708227 , -0.04105363, -0.13038684,  0.1087723 ,  0.26722184]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esSJoZRNOeNp",
        "outputId": "3d984cfb-a92e-49c5-c4a5-faa5ec6ee6bd"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 50)                48190600  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                816       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 48,191,433\n",
            "Trainable params: 48,191,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIKBjnkIO1R9"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbc9vMcO5qm"
      },
      "source": [
        "x_val = train_examples[:10000]\n",
        "partial_x_train = train_examples[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o-hkQ5PO_uf",
        "outputId": "80119e04-7559-44e6-a998-b6e30f224802"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "38/38 [==============================] - 5s 50ms/step - loss: 0.6930 - accuracy: 0.5278 - val_loss: 0.6904 - val_accuracy: 0.5293\n",
            "Epoch 2/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.6794 - accuracy: 0.5720 - val_loss: 0.6892 - val_accuracy: 0.5343\n",
            "Epoch 3/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.6659 - accuracy: 0.6026 - val_loss: 0.6883 - val_accuracy: 0.5342\n",
            "Epoch 4/40\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 0.6451 - accuracy: 0.6451 - val_loss: 0.6868 - val_accuracy: 0.5453\n",
            "Epoch 5/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.6137 - accuracy: 0.6957 - val_loss: 0.6905 - val_accuracy: 0.5438\n",
            "Epoch 6/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.5723 - accuracy: 0.7240 - val_loss: 0.6947 - val_accuracy: 0.5552\n",
            "Epoch 7/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.5294 - accuracy: 0.7555 - val_loss: 0.7079 - val_accuracy: 0.5668\n",
            "Epoch 8/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.4856 - accuracy: 0.7768 - val_loss: 0.7252 - val_accuracy: 0.5711\n",
            "Epoch 9/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.4406 - accuracy: 0.8011 - val_loss: 0.7515 - val_accuracy: 0.5683\n",
            "Epoch 10/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.4123 - accuracy: 0.8121 - val_loss: 0.7754 - val_accuracy: 0.5728\n",
            "Epoch 11/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.3849 - accuracy: 0.8254 - val_loss: 0.8099 - val_accuracy: 0.5770\n",
            "Epoch 12/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.3536 - accuracy: 0.8400 - val_loss: 0.8407 - val_accuracy: 0.5762\n",
            "Epoch 13/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.3364 - accuracy: 0.8444 - val_loss: 0.8764 - val_accuracy: 0.5787\n",
            "Epoch 14/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.3185 - accuracy: 0.8542 - val_loss: 0.9136 - val_accuracy: 0.5844\n",
            "Epoch 15/40\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 0.3046 - accuracy: 0.8602 - val_loss: 0.9434 - val_accuracy: 0.5758\n",
            "Epoch 16/40\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.2922 - accuracy: 0.8673 - val_loss: 0.9796 - val_accuracy: 0.5789\n",
            "Epoch 17/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.2818 - accuracy: 0.8711 - val_loss: 1.0077 - val_accuracy: 0.5816\n",
            "Epoch 18/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.2674 - accuracy: 0.8793 - val_loss: 1.0430 - val_accuracy: 0.5800\n",
            "Epoch 19/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.2575 - accuracy: 0.8841 - val_loss: 1.0877 - val_accuracy: 0.5802\n",
            "Epoch 20/40\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.2490 - accuracy: 0.8835 - val_loss: 1.1142 - val_accuracy: 0.5792\n",
            "Epoch 21/40\n",
            "38/38 [==============================] - 2s 45ms/step - loss: 0.2426 - accuracy: 0.8889 - val_loss: 1.1497 - val_accuracy: 0.5744\n",
            "Epoch 22/40\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.2425 - accuracy: 0.8856 - val_loss: 1.1828 - val_accuracy: 0.5778\n",
            "Epoch 23/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.2279 - accuracy: 0.8915 - val_loss: 1.2169 - val_accuracy: 0.5804\n",
            "Epoch 24/40\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.2287 - accuracy: 0.8942 - val_loss: 1.2414 - val_accuracy: 0.5795\n",
            "Epoch 25/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.2205 - accuracy: 0.8976 - val_loss: 1.2870 - val_accuracy: 0.5721\n",
            "Epoch 26/40\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.2204 - accuracy: 0.8951 - val_loss: 1.3199 - val_accuracy: 0.5830\n",
            "Epoch 27/40\n",
            "38/38 [==============================] - 2s 45ms/step - loss: 0.2125 - accuracy: 0.9007 - val_loss: 1.3370 - val_accuracy: 0.5761\n",
            "Epoch 28/40\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.2058 - accuracy: 0.9055 - val_loss: 1.3775 - val_accuracy: 0.5752\n",
            "Epoch 29/40\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.2063 - accuracy: 0.9037 - val_loss: 1.4050 - val_accuracy: 0.5769\n",
            "Epoch 30/40\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.2011 - accuracy: 0.9060 - val_loss: 1.4315 - val_accuracy: 0.5749\n",
            "Epoch 31/40\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.1969 - accuracy: 0.9059 - val_loss: 1.4584 - val_accuracy: 0.5775\n",
            "Epoch 32/40\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.1947 - accuracy: 0.9065 - val_loss: 1.4917 - val_accuracy: 0.5794\n",
            "Epoch 33/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.1936 - accuracy: 0.9050 - val_loss: 1.5192 - val_accuracy: 0.5769\n",
            "Epoch 34/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.1896 - accuracy: 0.9087 - val_loss: 1.5410 - val_accuracy: 0.5813\n",
            "Epoch 35/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.1914 - accuracy: 0.9052 - val_loss: 1.5744 - val_accuracy: 0.5807\n",
            "Epoch 36/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.1863 - accuracy: 0.9087 - val_loss: 1.5981 - val_accuracy: 0.5788\n",
            "Epoch 37/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.1788 - accuracy: 0.9124 - val_loss: 1.6223 - val_accuracy: 0.5758\n",
            "Epoch 38/40\n",
            "38/38 [==============================] - 2s 43ms/step - loss: 0.1774 - accuracy: 0.9132 - val_loss: 1.6521 - val_accuracy: 0.5753\n",
            "Epoch 39/40\n",
            "38/38 [==============================] - 2s 44ms/step - loss: 0.1777 - accuracy: 0.9125 - val_loss: 1.6752 - val_accuracy: 0.5747\n",
            "Epoch 40/40\n",
            "38/38 [==============================] - 2s 42ms/step - loss: 0.1731 - accuracy: 0.9155 - val_loss: 1.7016 - val_accuracy: 0.5730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP8UvPdTPD-B",
        "outputId": "05f3c808-20a8-4009-a406-c1459b0b4401"
      },
      "source": [
        "results = model.evaluate(test_examples, test_labels)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "229/229 [==============================] - 1s 3ms/step - loss: 1.6692 - accuracy: 0.5869\n",
            "[1.669185757637024, 0.5869000554084778]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}