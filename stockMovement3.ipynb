{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stockMovement3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJsiFvA46d3QY8SCO55hyT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vktiwary007/stock-move-eureka/blob/main/stockMovement3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt_cE5Bm2HTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4d9d60-ba48-4d36-b45c-abb995f6c981"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.4.1\n",
            "Eager mode:  True\n",
            "Hub version:  0.11.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhtkn5qPHLTA"
      },
      "source": [
        "import io\n",
        "#df = pd.read_csv('Apple60.csv', skiprows=0)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "df = pd.read_csv('Para_News15_Combined15.csv', sep=',', header=0)\n",
        "df[\"Movement\"].replace({-1: 0}, inplace=True)\n",
        "#data = df.loc[df['Stock'] == 'Apple']\n",
        "data = df\n",
        "#train_df = data\n",
        "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "4Qhd_OSJH9TD",
        "outputId": "495c6483-e864-4fd3-ccd4-38c1388a18a2"
      },
      "source": [
        "data[:10]"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>News</th>\n",
              "      <th>Movement</th>\n",
              "      <th>Stock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>www.businesswire.com</td>\n",
              "      <td>2017-12-07 20:00:00+00:00</td>\n",
              "      <td>NAPE Summit Week will also feature the annual ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>2017-12-18 20:05:00+00:00</td>\n",
              "      <td>With such a large revenue pie, naturally we be...</td>\n",
              "      <td>1</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>2017-12-26 13:48:00+00:00</td>\n",
              "      <td>1 . -- U.S. stock futures turned lower on Tues...</td>\n",
              "      <td>1</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>2017-12-27 13:35:00+00:00</td>\n",
              "      <td>1 . -- U.S. stock futures traded slightly high...</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>2017-12-28 13:13:00+00:00</td>\n",
              "      <td>2. Here Comes the Data The economic calendar i...</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>2017-12-28 13:13:00+00:00</td>\n",
              "      <td>Apple CEO Tim Cook Gets a Big Raise, but He'll...</td>\n",
              "      <td>1</td>\n",
              "      <td>Amazon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>2017-12-29 13:40:00+00:00</td>\n",
              "      <td>1. -- The Dow Sets Yet Another Record U.S. sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>2017-12-29 13:48:00+00:00</td>\n",
              "      <td>Cramer credited his daughters with turning him...</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>2017-12-29 13:48:00+00:00</td>\n",
              "      <td>For those with a little more time and know-how...</td>\n",
              "      <td>0</td>\n",
              "      <td>Amazon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>www.proactiveinvestors.co.uk</td>\n",
              "      <td>2018-01-02 13:01:00+00:00</td>\n",
              "      <td>Here are the stocks that are in play in pre-ma...</td>\n",
              "      <td>1</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Source                   DateTime  ... Movement   Stock\n",
              "0          www.businesswire.com  2017-12-07 20:00:00+00:00  ...        1   Apple\n",
              "1              seekingalpha.com  2017-12-18 20:05:00+00:00  ...        1   Apple\n",
              "2             www.thestreet.com  2017-12-26 13:48:00+00:00  ...        1   Apple\n",
              "3             www.thestreet.com  2017-12-27 13:35:00+00:00  ...        0   Apple\n",
              "4             www.thestreet.com  2017-12-28 13:13:00+00:00  ...        0   Apple\n",
              "5             www.thestreet.com  2017-12-28 13:13:00+00:00  ...        1  Amazon\n",
              "6             www.thestreet.com  2017-12-29 13:40:00+00:00  ...        0   Apple\n",
              "7             www.thestreet.com  2017-12-29 13:48:00+00:00  ...        0   Apple\n",
              "8             www.thestreet.com  2017-12-29 13:48:00+00:00  ...        0  Amazon\n",
              "9  www.proactiveinvestors.co.uk  2018-01-02 13:01:00+00:00  ...        1   Apple\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_zH1sgphjJ7",
        "outputId": "5101081a-a940-4e57-f767-6f0dfdec4958"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "MAX_NB_WORDS = 40000\n",
        "max_seq_len = 1000\n",
        "\n",
        "raw_docs_train = train_df['News'].tolist()\n",
        "#raw_docs_test = test_df['News'].tolist()\n",
        "\n",
        "print(raw_docs_train[:10])\n",
        "\n",
        "num_classes = 2\n",
        "processed_docs_train = []\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for doc in tqdm(raw_docs_train):\n",
        "  tokens = word_tokenize(doc)\n",
        "  filtered = [word for word in tokens if word not in stop_words]\n",
        "  processed_docs_train.append(\" \".join(filtered))\n",
        "\n",
        "\n"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 61/20479 [00:00<00:42, 481.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['MARKET COMFORT Loss-making Spotify, which has prioritized rapid growth over profit and whose closest rival is Apple Inc’s ( AAPL.O ) Apple Music, launched in 2008 and had 71 million subscribers at the end of 2017.', 'A key question heading into Wednesday is whether the flagging info tech sector can turn things around. Tuesday’s steep losses wiped out the sector’s 2018 gains and appeared to spread misery across Wall Street. Maybe a dose of positive data might help. The government said in its final estimate that Q4 GDP rose 2.9%. That was well above its prior estimate of 2.5%, and also above Wall Street analysts’ consensus of 2.6%. If you round up, that means growth continues to be near the 3% level, a definite improvement from the recent past. However, many analysts expect Q1 GDP growth to slow. On the whole, things seem to be getting overdone as the market tries to find an equilibrium. Over the last few days, there’s been some very emotional and very skittish trading, and it looks like many people don’t want to be carrying risk into a three-day weekend. As a reminder, the market is closed Friday for the Good Friday holiday. Before that, two trading days remain this week to see where info tech heads next. Early indications Wednesday point toward a possible rebound for the sector, as well as for some of the major industrial stocks like Boeing Co (NYSE: BA ) that have also been under pressure lately. However, recent rallies have faced tough sledding as sellers seem to have itchy trigger fingers. The technology flu roared back with a vengeance Tuesday. Worry spread across the FAANG stocks and over to Tesla Inc (NASDAQ: TSLA ) and NVIDIA Corporation (NASDAQ: NVDA ) as well. Some of the tech stocks appeared to be reacting to specific bad news, while others may have simply fallen in part due to general negativity throughout the sector. Facebook, Inc . (NASDAQ: FB ) lost more ground as it continued to wrestle with the data security issue, and Alphabet Inc (NASDAQ: GOOG ) (NASDAQ: GOOGL )shares might be sneezing from a few of those germs as well. Some analysts have pointed out that GOOG users might have similar privacy risks, and one question circulating around the market is how this might affect ad revenue for both of the tech giants going forward. The sickness spread to Twitter Inc (NYSE: TWTR ) as well. FB shares have now basically lost all of the gains they had made since early last July. The issues with FB and GOOG don’t necessarily explain, however, why shares of the other FAANGs ( Apple Inc (NASDAQ: AAPL ), Netflix, Inc. (NASDAQ: NFLX ), and Amazon,com, Inc. (NASDAQ: AMZN )) also suffered steep losses Tuesday. Their business models are quite different from those of GOOG and FB. It just seemed like selling became contagious across this closely-watched segment of the market. Meanwhile NVDA got hit by sellers after announcing a halt in its self-driving car project. TSLA fell more than 8% after the National Transportation Safety Board posted on Twitter it sent two investigators to look into the fatal crash of a Tesla vehicle in California last week, CNBC reported. TSLA shares are at one-year lows. As info tech took a beating, some investors appeared to seek safety in fixed income. The 10-year Treasury yield closed below 2.8% for the first time since early last month and fell to 2.76% by early Wednesday. From a technical standpoint, the reversal in the 10-year yield from near recent highs above 2.9% a week ago to below 2.8% now looks like it might be significant. Keep watch to see how this plays out over coming days. Though info tech suffered the most, other sectors also plunged Tuesday in a really messy day for the market. Nothing came close to the nearly 3.5% info tech losses, but financials and consumer discretionary both fell nearly 2%, continuing the recent poor showing by big bank stocks. The falling Treasury yields might have hurt banks. Traditional “safe havens” utilities and telecom were among the only sectors posting gains. The tech-heavy Nasdaq (COMP) had the day’s worst performance for the major indices with an almost 3% plunge. However, each of the biggies was down significantly, including the Russell 2000 (RUT) small-cap index and transports ($DJT). Somewhat surprisingly, one of the stocks that’s been under the most pressure lately, General Electric (GE), had a nice bounce Tuesday. There were rumors that Warren Buffett might buy a stake, Bloomberg reported. Buffett has ventured into downtrodden stocks in the past, though the GE talk is simply speculation for now. GE shares jumped more than 4%. Another thing to keep an eye on could be progress in solar energy after an announcement from Saudi Arabia and SoftBank (SFTBF) about the largest solar project ever, starting with an initial $1 billion investment from the SoftBank Vision Fund, of which Saudi Arabia is a prime backer. The project’s value could ultimately be high as $200 billion, CNN reported. It could be interesting to track the ramifications going forward for crude and solar power stocks. At times like these, technical factors often take on greater significance. Last Friday, the S&P 500 (SPX) fell to within just a few points of its 200-day moving average, and then bounced Monday after failing to move below that closely-watched level. Tuesday’s losses took it back to within view of its 200-day, which now sits at around 2,587 (see chart below). That could be a number to watch Wednesday, because a move below it might trigger technically-based selling. Crude prices had been on the upswing but slipped a bit early Wednesday on signs of growing U.S. supplies. The weekly government stockpiles report is due later this morning. Remember the warnings about continued volatility? They appeared to be on target Tuesday as the VIX climbed more than 10% at times on Tuesday. VIX did retreat a little early Wednesday but remained above 22. Looking at Tuesday’s downward stock market action and blistering volatility, the takeaway could be that this is a market having trouble holding onto rallies. Last year, everyone seemed in the mood to buy on the way up, not wanting to miss out on more gains. The trend now seems to be the opposite, where many people are selling rallies to get out before another dip. This trend could be especially prevalent here in the last week of the quarter, where there’s a three-day weekend ahead and many big firms are squaring up their books for Q1. In a few weeks, earnings season begins again, perhaps giving the market something firmer to hang its hat on and maybe, just maybe, easing some of this choppiness. Until then, long-term investors might want to keep themselves from focusing too much on the day-to-day moves, while daily traders might want to consider a very cautious approach. FIGURE 1: LONG TERM TRENDLINE AND 200 DAY MOVING AVERAGE. While uncertainty has ruled the markets in these volatile times, some chart watchers note the S&P 500 Index (SPX) has thus far failed to breach key support levels. Data source: S&P Dow Jones Indices. Chart source: The thinkorswim® platform from TD Ameritrade . For illustrative purposes only. Past performance does not guarantee future results. Inflation In Focus Tomorrow morning sees delivery of the closely-watched Personal Consumption Expenditures (PCE) prices report for February. Remember, this is one the Fed says it watches very closely, and the market is still on tenterhooks about prices. February’s consumer price index (CPI) and producer price index (PPI) didn’t seem too alarming, and neither have recent PCE reports. For instance, in January, the PCE price index rose 1.7% year-over-year for the third straight month while the core PCE Price Index was up 1.5% for the fourth straight month. Wall Street analysts’ consensus is for a rather mild 0.2% month-over-month rise in both the headline PCE index and core PCE prices in February, according to Briefing.com. That would actually be a slower pace than January’s 0.4% rise in the headline and 0.3% rise in core. If the data come in as analysts anticipate, it likely won’t do much to feed inflation fears on Wall Street. Fading Europe? One supposed truism in the markets over the last six months or so — and one that’s helped push the value of the U.S. dollar down and U.S. bond yields up — is that the euro zone is in recovery. However, doubts arose Tuesday when the European Commission reported that economic sentiment slipped for the third month in a row in March. The downbeat reading paired with falling inflation expectations for consumers and manufacturers alike, as well as earlier data suggesting loan growth and money supply in euro zone had also slowed, Reuters reported. It’s far from assured, but if Europe’s economy starts to lose its grip, U.S. bond prices might see less pressure and bond yields here could stay more contained. On the other hand, weaker conditions in Europe don’t necessarily bode well for U.S. companies doing business there. The next European Central Bank (ECB) meeting is in a month. Inflation and the Long-Term Investor If you’re investing for the long term, inflation can be one of the biggest enemies, steadily eroding the value of your money. That’s one reason many people invest in the first place, because historically, stock markets have risen faster than inflation (though past isn’t necessarily precedent). One thing to avoid is getting lulled into slumber by recent low inflation. Long-term investors should consider that current low unemployment has the potential to send wages up, possibly triggering a more inflationary environment. While that doesn’t necessarily mean a return of the 1970s when things got really out of hand, it is a reason to consider keeping your asset allocation in balance across various classes. Fixed income investments can sometimes suffer in an inflationary environment, while investors might be able to blunt some of the impact of rising prices with stocks that pay dividends, for instance. Information from TDA is not intended to be investment advice or construed as a recommendation or endorsement of any particular investment or investment strategy, and is for illustrative purposes only. Be sure to understand all risks involved with each strategy, including commission costs, before attempting to place any trade. © 2018 Benzinga.com. Benzinga does not provide investment advice. All rights reserved.', 'A video of the two men being removed by at least six officers from a Philadelphia Starbucks went viral. They were reportedly waiting for a business associate. It sparked outrage on social media with many people pointing out that Starbucks outlets are often full of people sitting on their Apple AAPL, -0.26% with (and without) a Starbucks coffee next to them.', 'ZWJ Investment Counsel Inc. Trims Position in Apple Inc. (AAPL) Posted by Donna Armstrong | Feb 26th, 2018 ZWJ Investment Counsel Inc. lowered its holdings in shares of Apple Inc. (NASDAQ:AAPL) by 5.5% in the 3rd quarter, according to its most recent disclosure with the SEC. The fund owned 182,226 shares of the iPhone maker’s stock after selling 10,553 shares during the period. Apple comprises 2.2% of ZWJ Investment Counsel Inc.’s holdings, making the stock its 10th largest holding. ZWJ Investment Counsel Inc. owned about 3,527.94% of Apple worth $28,085,000 as of its most recent SEC filing. A number of research firms have commented on AAPL. BidaskClub upgraded shares of Apple from a “sell” rating to a “hold” rating in a report on Saturday, February 17th. Raymond James Financial restated a “market perform” rating on shares of Apple in a report on Friday, February 16th. Vetr cut shares of Apple from a “strong-buy” rating to a “buy” rating and set a $187.18 price target for the company. in a report on Wednesday, February 14th. Bank of America restated an “outperform” rating and issued a $220.00 price target on shares of Apple in a report on Thursday, February 8th. Finally, ValuEngine cut shares of Apple from a “buy” rating to a “hold” rating in a report on Thursday, February 8th. One investment analyst has rated the stock with a sell rating, eighteen have issued a hold rating, thirty-three have issued a buy rating and one has issued a strong buy rating to the stock. The stock currently has a consensus rating of “Buy” and a consensus target price of $201.64. Shares of Apple Inc. ( AAPL ) opened at $175.50 on Monday. The company has a market cap of $890,490.00, a PE ratio of 17.17, a price-to-earnings-growth ratio of 1.32 and a beta of 1.33. The company has a debt-to-equity ratio of 0.74, a current ratio of 1.24 and a quick ratio of 1.20. Apple Inc. has a 12-month low of $135.28 and a 12-month high of $180.10. Apple (NASDAQ:AAPL) last posted its earnings results on Thursday, February 1st. The iPhone maker reported $3.89 earnings per share for the quarter, topping the consensus estimate of $3.82 by $0.07. The firm had revenue of $88.29 billion during the quarter, compared to the consensus estimate of $87.62 billion. Apple had a net margin of 21.13% and a return on equity of 37.37%. The company’s revenue was up 12.7% on a year-over-year basis. During the same quarter last year, the company earned $3.36 earnings per share. equities analysts forecast that Apple Inc. will post 11.43 EPS for the current year. The firm also recently announced a quarterly dividend, which was paid on Thursday, February 15th. Stockholders of record on Monday, February 12th were paid a $0.63 dividend. The ex-dividend date was Friday, February 9th. This represents a $2.52 annualized dividend and a dividend yield of 1.44%. Apple’s payout ratio is 24.66%. COPYRIGHT VIOLATION WARNING: “ZWJ Investment Counsel Inc. Trims Position in Apple Inc. (AAPL)” was first posted by The Lincolnian Online and is the sole property of of The Lincolnian Online. If you are viewing this article on another site, it was copied illegally and reposted in violation of United States & international trademark and copyright law. The correct version of this article can be read at https://www.thelincolnianonline.com/2018/02/26/zwj-investment-counsel-inc-has-28-09-million-stake-in-apple-inc-aapl-updated.html. ', 'Wedge Capital Management L L P, which manages about $10.84B and $11.15 billion US Long portfolio, upped its stake in Apple Inc. (NASDAQ:AAPL) by 51,171 shares to 373,155 shares, valued at $63.15M in 2017Q4, according to the filing. It also increased its holding in Cit Group Inc. (NYSE:CIT) by 11,331 shares in the quarter, for a total of 1.54 million shares, and has risen its stake in Commerce Bancshares Inc. (NASDAQ:CBSH).', 'The daughter that Steve Jobs once disavowed is writing a memoir about her childhood (AAPL) Posted By: BusinessInsider March 16, 2018 Lisa Brennan-Jobs, the daughter of Steve Jobs, is writing a memoir about her childhood. The legendary entrepreneur initially refused to believe that Brennan-Jobs, now 39, was his child. Jobs was “rarely present in her life” and “cold, critical and unpredictable,” the publisher says. ', '“I calculate that the implied effect of Taiwan Semiconductor’s guidance drop to Apple’s full-year net earnings would barely breach $7 billion,” Martins writes. “On the other hand, AAPL has lost a whopping $65 billion in market cap over the past few days – way too much for my taste, considering the worst-case financial impact to the company.” MacDailyNews Take: AAPL was undervalued before the recent BS-fest. It’s even more undervalued now. ', '– Staff Writer, Atlanta Business Chronicle Feb 22, 2018, 11:44am EST When it comes to corporate site selection — “talent, talent, talent” is the new “location, location, location.” With its $5 billion “HQ2” derby, Seattle-based Amazon.com (Nasdaq: AMZN) has “probably altered” how corporate relocations and expansions will occur in the next decade, according to a real estate economist. That shift puts Atlanta — an emerging technology industry hub and millennial destination — in a winning position. K.C. Conway , chief economist for the commercial real estate trade organization the CCIM Institute , authored a white paper that discusses how Amazon’s HQ2 site selection process is “a reset button that will likely have implications far beyond Amazon.” “A close reading of the RFP reveals that the search seems less about incentives and more about workforce solutions and corporate culture fit,” Conway wrote. “Other rising and transformative technology companies may use similar criteria for future site selections.” Workforce availability is the most important factor driving corporate relocation and expansion decisions today. “Without it, their growth stalls out,” Conway argues. Atlanta not only has the workforce — it has the fundamentals that help it recruit more of it every day. And, Amazon is paying attention. The company is building out its Amazon Web Services and A9.com offices in Buckhead. Amazon is also quietly developing a logistics command center and technology development hub in Midtown. Real estate services firm CBRE Inc. ranked Atlanta fifth in tech talent among 50 of the largest cities in the U.S. and Canada. Atlanta was bested by San Francisco, Seattle, New York and Washington, D.C., according to CBRE’s (NYSE: CBRE) 2017 Tech Talent Scoring report, which measured each market’s depth, vitality and attractiveness to companies seeking tech talent and to tech workers seeking employment. While tech talent in Atlanta accounted for just 5 percent of total jobs in the city, tech talent grew nearly 15 percent from 2011 to 2016, the report noted. Millennials — the demographic coveted by the tech industry — accounts for about 20 percent of Atlanta’s population. Georgia Tech is undoubtedly the engine powering Atlanta’s tech industry — generating research and talent that feeds the startup ecosystem and established tech. The school’s computer science program is ranked No. 5 in the world, according to the Times Higher Education World University Rankings. Atlanta’s tech startup ecosystem has bloomed in the past several years as the industry gains attention nationally with the rise of companies such as Amazon, Tesla Inc. (Nasdaq: TSLA), Apple Inc. (Nasdaq: AAPL) and Google . A wave of tech accelerator programs ( Flashpoint), business incubators ( ATDC) and startup hubs ( Atlanta Tech Village) provide the educational, cultural and physical infrastructure to nurture the next generation of companies and company creators. “Atlanta is developing a profile for creativity, for talent and for an aggressive desire to court new industries,” noted Craig Lesser , managing partner with The Pendleton Group, an economic development consulting firm. Conway identified Atlanta as one of three cities in the U.S., along with Pittsburgh and Columbus, Ohio, that will be the “top contenders for corporate site selections in the coming years.” Atlanta is part of the “Golden Triangle,” a phrase Conway coined that refers to a region encompassed by the Great Lakes to the north, Texas to the southwest, and Georgia, South Carolina, and Florida to the southeast. “The Golden Triangle produces about one-half the U.S. annual GDP and a skilled workforce, and it’s the epicenter of America’s new supply chain,” Conway said. Despite being the odds-on favorite for the HQ2 selection, Atlanta has significant hurdles to overcome, Conway said. He noticed the metro region’s failure to address its traffic congestion, develop a regional transportation plan, or pass a Transportation Special Purpose Local Option Sales Tax to fund transportation projects. “The spring 2017 I-85 bridge collapse highlighted how serious Atlanta’s traffic problems have become, and that those problems have been ignored,” Conway noted. – Staff Writer, Atlanta Business Chronicle Feb 22, 2018, 11:44am EST Related Content', \"Apple Inc. ( AAPL ) is +2.2 at $227.94, with 223,859 shares traded. Over the last four weeks they have had 3 up revisions for the earnings forecast, for the fiscal quarter ending Sep 2018. The consensus EPS forecast is $2.77. AAPL's current last sale is 97% of the target price of $235.\", 'Laurel Grove Capital Llc, which manages about $236.05M and $193.20M US Long portfolio, decreased its stake in Wabtec Corp (NYSE:WAB) by 4,015 shares to 57,935 shares, valued at $4.72M in 2017Q4, according to the filing. It also reduced its holding in Apple Inc (NASDAQ:AAPL) by 4,531 shares in the quarter, leaving it with 48,235 shares, and cut its stake in Vodafone Group Adr (NASDAQ:VOD).   Peter Kolinski  ']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20479/20479 [00:32<00:00, 627.56it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvcNVVJv2wvY",
        "outputId": "e7271061-718f-4ac7-9c18-54682230c842"
      },
      "source": [
        "raw_docs_test = test_df['News'].tolist()\n",
        "processed_docs_test = []\n",
        "\n",
        "for doc in tqdm(raw_docs_test):\n",
        "  tokens = word_tokenize(doc)\n",
        "  filtered = [word for word in tokens if word not in stop_words]\n",
        "  processed_docs_test.append(\" \".join(filtered))"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5120/5120 [00:08<00:00, 635.48it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI4pOeNs7kqK",
        "outputId": "1fa6ef2d-3c0b-4ba2-c681-aaea50f68609"
      },
      "source": [
        "test_data = pd.read_csv('Amazon60_Major.csv', sep=',', header=0)\n",
        "\n",
        "test_corpus = test_data['News'].tolist()\n",
        "\n",
        "processed_test_sample = []\n",
        "for doc in tqdm(test_corpus):\n",
        "  tokens = word_tokenize(doc)\n",
        "  filtered = [word for word in tokens if word not in stop_words]\n",
        "  processed_test_sample.append(\" \".join(filtered))"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 229/229 [00:00<00:00, 818.25it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpUfiGO1AeB9",
        "outputId": "80c76590-8aa7-4f83-9f83-05c2887d45e8"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(processed_docs_train + processed_docs_test)  \n",
        "#tokenizer.fit_on_texts(processed_docs_train) \n",
        "vocab_length = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(vocab_length)"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6bTPyVFDPxh",
        "outputId": "44ebf48f-6627-4020-f855-d680f8294e90"
      },
      "source": [
        "MAX_NB_WORDS = vocab_length\n",
        "max_seq_len = 1000\n",
        "\n",
        "word_seq_train = tokenizer.texts_to_sequences(processed_docs_train)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "word_seq_train = pad_sequences(word_seq_train, maxlen=max_seq_len)\n",
        "\n",
        "print(len(word_index))"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odwuwGhk27_7"
      },
      "source": [
        "word_seq_test = tokenizer.texts_to_sequences(processed_docs_test)\n",
        "\n",
        "word_seq_test = pad_sequences(word_seq_test, maxlen=max_seq_len)\n"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hov_28v-28Yz"
      },
      "source": [
        "word_seq_testsample = tokenizer.texts_to_sequences(processed_test_sample)\n",
        "\n",
        "word_seq_testsample = pad_sequences(word_seq_testsample, maxlen=max_seq_len)"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "1qzxfGCAcZHT",
        "outputId": "12b237ad-010e-421b-e2eb-8f937318222f"
      },
      "source": [
        "import requests, zipfile, io\n",
        "zip_file_url = \"https://nlp.stanford.edu/data/glove.twitter.27B.zip\"\n",
        "r = requests.get(zip_file_url)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "\n",
        "print(\"GloVE available locally\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-a0043ba0905b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mzip_file_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://nlp.stanford.edu/data/glove.twitter.27B.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_file_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;31m# Resolve redirects if allowed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Shuffle things around if there's history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;31m# Resolve redirects if allowed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;31m# Shuffle things around if there's history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0madapter_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m                 )\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBKql0OIg5eW",
        "outputId": "7e2f9066-1906-4892-ed1d-8b9e1dd97682"
      },
      "source": [
        "import codecs\n",
        "\n",
        "embeddings_index = {}\n",
        "#f = codecs.open(‘crawl-300d-2M.vec’, encoding=’utf-8')\n",
        "# for Glove\n",
        "f = codecs.open('glove.twitter.27B.100d.txt', encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "  values = line.rstrip().rsplit(' ')\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193515it [00:55, 21673.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esSJoZRNOeNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aff3f0f-a7fe-43ef-94dd-312ba9b988df"
      },
      "source": [
        "words_not_found = []\n",
        "embed_dim = 100\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index)+1)\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i >= nb_words:\n",
        "     continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  \n",
        "  if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "     embedding_matrix[i] = embedding_vector\n",
        "  else:\n",
        "     words_not_found.append(word)\n",
        "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of null word embeddings: 16840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIKBjnkIO1R9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ff6ad7-b212-447c-d10f-5abeed29e45d"
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Embedding, Bidirectional, Dense, Dropout, LSTM, Flatten, Conv1D, MaxPooling1D, Activation\n",
        "from keras.initializers import Constant\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Embedding(nb_words, embed_dim, input_length=max_seq_len, weights=[embedding_matrix],trainable=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, 1000, 100)         4664700   \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 1000, 100)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 996, 64)           32064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_18 (MaxPooling (None, 249, 64)           0         \n",
            "_________________________________________________________________\n",
            "lstm_19 (LSTM)               (None, 100)               66000     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 4,762,865\n",
            "Trainable params: 98,165\n",
            "Non-trainable params: 4,664,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbc9vMcO5qm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3931715-3e61-4e4f-decb-783c9695bd70"
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "labels = to_categorical(np.asarray(train_df['Movement']))\n",
        "y_train = np.array(train_df['Movement'])\n",
        "\n",
        "print(labels[:10])\n",
        "print(y_train[:10])\n"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "[1 1 0 1 0 0 0 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPdG5lzNsChK"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3iLcVYWI3Ax",
        "outputId": "5e30d482-7035-4a27-dc70-85411ddd8d45"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "history = model.fit(word_seq_train, y_train, epochs=15)"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "640/640 [==============================] - 13s 18ms/step - loss: 0.6979 - accuracy: 0.4989 - f1_m: 0.3269 - precision_m: 0.3725 - recall_m: 0.4040\n",
            "Epoch 2/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.6898 - accuracy: 0.5295 - f1_m: 0.4395 - precision_m: 0.5520 - recall_m: 0.4544\n",
            "Epoch 3/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.6799 - accuracy: 0.5671 - f1_m: 0.5132 - precision_m: 0.5786 - recall_m: 0.5358\n",
            "Epoch 4/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.6596 - accuracy: 0.6024 - f1_m: 0.5613 - precision_m: 0.6097 - recall_m: 0.5517\n",
            "Epoch 5/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.6326 - accuracy: 0.6334 - f1_m: 0.6004 - precision_m: 0.6329 - recall_m: 0.5947\n",
            "Epoch 6/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.6107 - accuracy: 0.6571 - f1_m: 0.6237 - precision_m: 0.6573 - recall_m: 0.6190\n",
            "Epoch 7/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.5799 - accuracy: 0.6865 - f1_m: 0.6674 - precision_m: 0.6864 - recall_m: 0.6670\n",
            "Epoch 8/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.5575 - accuracy: 0.7039 - f1_m: 0.6818 - precision_m: 0.7090 - recall_m: 0.6744\n",
            "Epoch 9/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.5454 - accuracy: 0.7068 - f1_m: 0.6893 - precision_m: 0.7135 - recall_m: 0.6829\n",
            "Epoch 10/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.5282 - accuracy: 0.7170 - f1_m: 0.7016 - precision_m: 0.7273 - recall_m: 0.6927\n",
            "Epoch 11/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.5138 - accuracy: 0.7312 - f1_m: 0.7107 - precision_m: 0.7362 - recall_m: 0.7024\n",
            "Epoch 12/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.5004 - accuracy: 0.7413 - f1_m: 0.7237 - precision_m: 0.7492 - recall_m: 0.7148\n",
            "Epoch 13/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.4908 - accuracy: 0.7483 - f1_m: 0.7294 - precision_m: 0.7520 - recall_m: 0.7231\n",
            "Epoch 14/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.4791 - accuracy: 0.7483 - f1_m: 0.7344 - precision_m: 0.7525 - recall_m: 0.7302\n",
            "Epoch 15/15\n",
            "640/640 [==============================] - 11s 18ms/step - loss: 0.4851 - accuracy: 0.7531 - f1_m: 0.7402 - precision_m: 0.7560 - recall_m: 0.7384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrzOz3a9HEOE",
        "outputId": "6c1332c4-9972-4ab0-b87d-38cd4e6fac4a"
      },
      "source": [
        "y_test1 = np.array(test_df['Movement'])\n",
        "y_test2 = to_categorical(np.asarray(test_df['Movement']))\n",
        "probas = model.predict(word_seq_test)\n",
        "predict_labels = (probas < 0.5).astype(np.int)\n",
        "\n",
        "test_df[\"Movement\"].replace({0: -1}, inplace=True)\n",
        "#test_df['Predicted'] = predict_labels\n",
        "predict_labels = pd.DataFrame(predict_labels)\n",
        "predict_labels.replace({0: -1}, inplace=True)\n",
        "predict_labels.to_csv('test_label.csv')\n",
        "test_df.to_csv('test_news.csv')\n",
        "\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate(word_seq_test, y_test1, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))\n",
        "print('loss: %f' % (loss))\n",
        "print('f1: %f' % (f1_score))\n",
        "print('precision: %f' % (precision))\n",
        "print('recall: %f' % (recall))"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 54.414064\n",
            "loss: 0.820437\n",
            "f1: 0.488266\n",
            "precision: 0.541276\n",
            "recall: 0.460953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO_GbloIf2IH",
        "outputId": "7db501df-3e6d-4bea-b73c-1f78ce8be45b"
      },
      "source": [
        "test_data[\"Movement\"].replace({-1: 0}, inplace=True)\n",
        "y_testsample = np.array(test_data['Movement'])\n",
        "probas = model.predict(word_seq_testsample)\n",
        "predict_labels = (probas < 0.5).astype(np.int)\n",
        "\n",
        "print(predict_labels)\n",
        "np.savetxt(\"foo.csv\", predict_labels, delimiter=\",\")\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate(word_seq_testsample, y_testsample, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))\n",
        "print('loss: %f' % (loss*100))\n",
        "print('f1: %f' % (f1_score))\n",
        "print('precision: %f' % (precision))\n",
        "print('recall: %f' % (recall))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [1]\n",
            " [0]]\n",
            "Accuracy: 67.945069\n",
            "loss: 59.957469\n",
            "f1: 0.650129\n",
            "precision: 0.656496\n",
            "recall: 0.694183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnCUiSNRlpJ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}