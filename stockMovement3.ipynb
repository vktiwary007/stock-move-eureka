{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stockMovement3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOrABETMQUB0NewlcBVt7yk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vktiwary007/stock-move-eureka/blob/main/stockMovement3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt_cE5Bm2HTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9bb99ab-7cba-4208-b150-16a5d888d6e0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.4.1\n",
            "Eager mode:  True\n",
            "Hub version:  0.11.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhtkn5qPHLTA"
      },
      "source": [
        "import io\n",
        "#df = pd.read_csv('Apple60.csv', skiprows=0)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "df = pd.read_csv('Para_News60_Combined60.csv', sep=',', header=0)\n",
        "df[\"Movement\"].replace({-1: 0}, inplace=True)\n",
        "data = df.loc[df['Stock'] == 'Apple']\n",
        "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "4Qhd_OSJH9TD",
        "outputId": "71ef6a5c-652c-425b-a0b6-14db534ad603"
      },
      "source": [
        "data[:10]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>News</th>\n",
              "      <th>Movement</th>\n",
              "      <th>Stock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>www.businesswire.com</td>\n",
              "      <td>2017-12-07 20:00:00+00:00</td>\n",
              "      <td>NAPE Summit Week will also feature the annual ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>2017-12-14 11:42:00+00:00</td>\n",
              "      <td>Bearish Calls Lumentum (NASDAQ: LITE ): It's a...</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>2017-12-14 12:31:00+00:00</td>\n",
              "      <td>The areas to be concerned are that there are f...</td>\n",
              "      <td>1</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>2017-12-15 12:04:00+00:00</td>\n",
              "      <td>Amazon will soon resume selling the Apple TV (...</td>\n",
              "      <td>1</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>2017-12-18 20:05:00+00:00</td>\n",
              "      <td>With such a large revenue pie, naturally we be...</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>2017-12-21 12:04:00+00:00</td>\n",
              "      <td>Facing questions from tech analysts, Apple (NA...</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>2017-12-21 12:27:00+00:00</td>\n",
              "      <td>Cramer and the AAP team say investors need to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>2017-12-22 11:51:00+00:00</td>\n",
              "      <td>One day after Apple acknowledged that it has b...</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>www.thestreet.com</td>\n",
              "      <td>2017-12-26 13:48:00+00:00</td>\n",
              "      <td>1 . -- U.S. stock futures turned lower on Tues...</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>seekingalpha.com</td>\n",
              "      <td>2017-12-27 11:43:00+00:00</td>\n",
              "      <td>Shares in Apple and several of its suppliers f...</td>\n",
              "      <td>0</td>\n",
              "      <td>Apple</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Source                   DateTime  ... Movement  Stock\n",
              "0   www.businesswire.com  2017-12-07 20:00:00+00:00  ...        1  Apple\n",
              "1       seekingalpha.com  2017-12-14 11:42:00+00:00  ...        0  Apple\n",
              "2       seekingalpha.com  2017-12-14 12:31:00+00:00  ...        1  Apple\n",
              "3       seekingalpha.com  2017-12-15 12:04:00+00:00  ...        1  Apple\n",
              "5       seekingalpha.com  2017-12-18 20:05:00+00:00  ...        0  Apple\n",
              "7       seekingalpha.com  2017-12-21 12:04:00+00:00  ...        0  Apple\n",
              "9      www.thestreet.com  2017-12-21 12:27:00+00:00  ...        0  Apple\n",
              "10      seekingalpha.com  2017-12-22 11:51:00+00:00  ...        0  Apple\n",
              "11     www.thestreet.com  2017-12-26 13:48:00+00:00  ...        0  Apple\n",
              "13      seekingalpha.com  2017-12-27 11:43:00+00:00  ...        0  Apple\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_zH1sgphjJ7",
        "outputId": "209fed2f-4c23-4bb0-9039-8274a9451d08"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "MAX_NB_WORDS = 40000\n",
        "max_seq_len = 1000\n",
        "\n",
        "raw_docs_train = train_df['News'].tolist()\n",
        "raw_docs_test = test_df['News'].tolist()\n",
        "\n",
        "print(raw_docs_train[:10])\n",
        "\n",
        "num_classes = 2\n",
        "processed_docs_train = []\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for doc in tqdm(raw_docs_train):\n",
        "  tokens = word_tokenize(doc)\n",
        "  filtered = [word for word in tokens if word not in stop_words]\n",
        "  processed_docs_train.append(\" \".join(filtered))\n",
        "processed_docs_test = []\n",
        "\n",
        "for doc in tqdm(raw_docs_test):\n",
        "  tokens = word_tokenize(doc)\n",
        "  filtered = [word for word in tokens if word not in stop_words]\n",
        "  processed_docs_test.append(\" \".join(filtered))\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 50/17276 [00:00<00:38, 450.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['For much of the past year, the trade war has disrupted the flow of hundreds of billions of dollars worth of goods and hit the global economy. Official data this week showed manufacturing activity slowed in both countries, and companies such as Apple Inc ( AAPL.O ) and Cargill Inc [CARG.UL] said the trade battle had hit earnings.', \"U.S. stocks fell on Friday, with the S&P 500 returning to negative territory for the year as losses accelerated in midday trading. The benchmark index SPX, -0.85% lost 0.8%, and is now down less than 0.1% for 2018 thus far. While the S&P has been negative for the year multiple times in 2018, it had recently returned to the green. It has traded in positive territory for the year for the past four sessions. The Dow Jones Industrial Average DJIA, -0.82% fell 0.8% on Friday, bringing its year-to-date move to a drop of 1%. The Nasdaq Composite Index COMP, -1.27% fell 1.1% on Friday, but remains up 3.7% for the year. The day's losses were widespread, pressured by weakness in the energy sector and by a sharp decline in Apple Inc. AAPL, -4.10% \", 'As Apple INC (AAPL) Valuation Declined, Shareholder Texas Permanent School Fund Has Trimmed StakeInvestors sentiment increased to 0.73 in 2017 Q4. Its up 0.03, from 0.7 in 2017Q3. It increased, as 50 investors sold AAPL shares while 1023 reduced holdings. 151 funds opened positions while 637 raised stakes. 2.98 billion shares or 0.18% more from 2.97 billion shares in 2017Q3 were reported. Cambridge Fincl Group holds 3.24% or 38,797 shares. Wharton Business Grp Ltd Llc holds 2.72% or 155,897 shares in its portfolio. Brouwer Janachowski Ltd Limited Liability Company has 0.25% invested in Apple Inc. (NASDAQ:AAPL) for 7,931 shares. Cookson Peirce & Inc has invested 2.66% in Apple Inc. (NASDAQ:AAPL). Plante Moran Fincl Advisors Ltd Llc holds 33,725 shares. 324,692 are held by Salem Invest Counselors. Zevin Asset Mngmt Limited Liability owns 1.59% invested in Apple Inc. (NASDAQ:AAPL) for 41,402 shares. Confluence Wealth Management Limited Co stated it has 1.35% in Apple Inc. (NASDAQ:AAPL). Hikari Tsushin Inc reported 7,975 shares. 50,557 were accumulated by Cumberland. First Hawaiian Savings Bank holds 0.15% or 7,168 shares. Old Mutual Customised Solutions (Proprietary) accumulated 1.4% or 80,766 shares. Toth Advisory holds 21,271 shares or 0.85% of its portfolio. Rafferty Asset Mgmt Lc owns 31,088 shares or 0.09% of their US portfolio. Daniel Devine Company holds 5.92% or 48,398 shares.Since December 7, 2017, it had 0 insider buys, and 8 selling transactions for $42.88 million activity. $11.56M worth of Apple Inc. (NASDAQ:AAPL) shares were sold by SCHILLER PHILIP W. $6.75M worth of Apple Inc. (NASDAQ:AAPL) shares were sold by AHRENDTS ANGELA J. Riccio Daniel J. sold $2.65 million worth of stock. Another trade for 35,000 shares valued at $6.51 million was sold by LEVINSON ARTHUR D. 15,653 shares were sold by WILLIAMS JEFFREY E, worth $2.90M on Tuesday, May 8.Texas Permanent School Fund decreased its stake in Apple Inc (AAPL) by 2.08% based on its latest 2017Q4 regulatory filing with the SEC. Texas Permanent School Fund sold 29,826 shares as the company’s stock declined 3.81% with the market. The institutional investor held 1.40 million shares of the computer manufacturing company at the end of 2017Q4, valued at $237.20M, down from 1.43M at the end of the previous reported quarter. Texas Permanent School Fund who had been investing in Apple Inc for a number of months, seems to be less bullish one the $915.74 billion market cap company. The stock decreased 0.36% or $0.68 during the last trading session, reaching $186.31. About 16.17 million shares traded. Apple Inc. (NASDAQ:AAPL) has risen 19.49% since May 21, 2017 and is uptrending. It has outperformed by 7.94% the S&P500.Analysts await Apple Inc. (NASDAQ:AAPL) to report earnings on August, 7. They expect $2.19 earnings per share, up 31.14 % or $0.52 from last year’s $1.67 per share. AAPL’s profit will be $10.76 billion for 21.27 P/E if the $2.19 EPS becomes a reality. After $2.73 actual earnings per share reported by Apple Inc. for the previous quarter, Wall Street now forecasts -19.78 % negative EPS growth.More notable recent Apple Inc. (NASDAQ:AAPL) news were published by: Nasdaq.com which released: “Thursday’s Vital Data: Facebook, Inc. (FB), Apple Inc. (AAPL) and Alibaba Group Holding Ltd (BABA)” on May 17, 2018, also Fool.com with their article: “Why Buffett Keeps Buying Apple” published on May 19, 2018, Livetradingnews.com published: “Apple Inc. (NASDAQ:AAPL) Upward Trend” on May 17, 2018. More interesting news about Apple Inc. (NASDAQ:AAPL) were released by: 247Wallst.com and their article: “Analysts Jumping All Over Their Apple and iPhone Calls” published on May 02, 2018 as well as Seekingalpha.com ‘s news article titled: “Apple’s Dividend: An Opportunity Wasted” with publication date: May 15, 2018. Apple Inc. (NASDAQ:AAPL) Ratings CoverageAmong 36 analysts covering Apple ( NASDAQ:AAPL ), 20 have Buy rating, 0 Sell and 16 Hold. Therefore 56% are positive. Apple has $235 highest and $157 lowest target. $196.76’s average target is 5.61% above currents $186.31 stock price. Apple had 82 analyst reports since November 27, 2017 according to SRatingsIntel. The firm has “Buy” rating by UBS given on Wednesday, May 2. The firm earned “Buy” rating on Friday, February 2 by Canaccord Genuity. The rating was maintained by Piper Jaffray on Tuesday, January 2 with “Buy”. The stock of Apple Inc. (NASDAQ:AAPL) earned “Hold” rating by Bernstein on Friday, February 2. Atlantic Securities downgraded the shares of AAPL in report on Monday, January 22 to “Neutral” rating. UBS maintained Apple Inc. (NASDAQ:AAPL) rating on Friday, January 5. UBS has “Buy” rating and $190.0 target. UBS maintained it with “Buy” rating and $190.0 target in Monday, November 27 report. On Wednesday, March 7 the stock rating was maintained by Rosenblatt with “Buy”. The rating was maintained by Canaccord Genuity with “Buy” on Tuesday, January 23. The rating was maintained by Bank of America with “Buy” on Wednesday, January 17. ', 'More news for Boston Scientific Corporation (NYSE:BSX) were recently published by: Streetinsider.com , which released: “JANA Shows New Stakes in Apple (AAPL), Boston Scientific (BSX), Dropbox (DBX), iQIYI (IQ) (more..) -13F” on May 15, 2018. Forbes.com ‘s article titled: “A Quick Snapshot Of Boston Scientific’s Rhythm Management & Neuro Segment” and published on May 16, 2018 is yet another important article. Adrian Erickson ', 'On the flip side, group, representing a quarter of the broader market by itself -- is leading to the downside with a loss of 1.1%. Tech stocks are broadly lower, with mega caps like Apple (AAPL 193.35, -0.63), Microsoft (MSFT 101.60, -0.88), Facebook (FB 188.05, -3.29), and Alphabet (GOOG 1123.91, -12.97) down between 0.3% and 1.2%. Chipmakers are also weak, evidenced by a 1.2% decline in the PHLX Semiconductor Index. The health care group (-0.3%) is also a notable laggard.', 'Apple ( AAPL.O ), which is due to report earnings after the bell on Tuesday, was down 0.9 percent.', '– Reporter, Nashville 7:41am CDT Three Nashville-area executives and a U.S. senator from Tennessee are among the most influential people in the health care industry for 2018, according to Modern Healthcare, which released its annual list of the industry’s 100 most influential people this week. HCA Healthcare Inc. (NYSE: HCA) Chairman and CEO Milton Johnson led the pack of local leaders on the list, coming in at No. 14, followed by U.S. Sen. Lamar Alexander , who is chairman of the Senate’s Health, Education, Labor and Pensions Committee, at No. 31. Lifepoint Health (Nasdaq: LPNT) Chairman and CEO Bill Carpenter, whose company was purchased by private equity firm Apollo Global Management for $5.6 billion in July, made the biggest jump among local executives from last year , moving from the 73rd to the 38th most influential person in health care. This year, Carpenter’s No. 73 ranking was awarded to Community Health Systems Inc. (NYSE: CYH) Chairman and CEO Wayne Smith , who dropped from No.46 in 2017. Modern Healthcare, which compiled the list based on reader votes and editorial opinions, added a new “disruptor” classification to a group of leaders this year. Twelve executives were given a No. 2 ranking and the disruptor distinction, highlighted by Aetna Chairman and CEO Mark Bertolini , Amazon Inc. (Nasdaq: AMZN) Chairman and CEO Jeff Bezos and Apple Inc. (Nasdaq: AAPL) CEO Tim Cook . Bezos and leaders from Berkshire Hathaway Inc. (NYSE: BRK.A) and JP Morgan Chase & Co. (NYSE: JPM) announced in January they were joining forces to create their own health care company, while Apple released an electronic health record app this year and supplied HCA with 100,000 iPhones to be used in hospitals. President Donald Trump was named the most influential person in health care for 2018. HCA President of Clinical Services and Chief Medical Officer Dr. Jonathan Perlin was left off the 2018 list, after coming in at No. 77 last year. He ranked 14th on Modern Healthcare’s list of the most influential physician executives and leaders in 2018, released earlier this year.', 'Randolph Co Inc lifted its position in Apple (NASDAQ:AAPL) by 0.4% in the fourth quarter, according to its most recent Form 13F filing with the Securities and Exchange Commission. The fund owned 192,079 shares of the iPhone maker’s stock after buying an additional 684 shares during the quarter. Apple comprises approximately 5.5% of Randolph Co Inc’s holdings, making the stock its 2nd largest position. Randolph Co Inc’s holdings in Apple were worth $32,506,000 at the end of the most recent reporting period.Several research firms recently commented on AAPL. DZ Bank reiterated a “buy” rating on shares of Apple in a research note on Thursday, May 3rd. Atlantic Securities reiterated a “neutral” rating and set a $185.00 target price on shares of Apple in a research note on Wednesday, May 2nd. BidaskClub upgraded shares of Apple from a “hold” rating to a “buy” rating in a research note on Wednesday. Citigroup reissued a “focus list” rating and issued a $142.20 price target (up previously from $100.00) on shares of Apple in a report on Wednesday, May 2nd. Finally, Zacks Investment Research raised shares of Apple from a “sell” rating to a “hold” rating in a report on Thursday, May 3rd. One equities research analyst has rated the stock with a sell rating, sixteen have issued a hold rating, thirty-four have given a buy rating and two have assigned a strong buy rating to the stock. The company has a consensus rating of “Buy” and a consensus price target of $204.00. Shares of NASDAQ:AAPL opened at $186.05 on Wednesday. The company has a market capitalization of $939.50 billion, a P/E ratio of 20.20, a PEG ratio of 1.38 and a beta of 1.26. The company has a debt-to-equity ratio of 0.80, a quick ratio of 1.37 and a current ratio of 1.46. Apple has a fifty-two week low of $142.20 and a fifty-two week high of $187.67.Apple (NASDAQ:AAPL) last announced its quarterly earnings results on Tuesday, May 1st. The iPhone maker reported $2.73 earnings per share for the quarter, beating analysts’ consensus estimates of $2.69 by $0.04. The business had revenue of $61.14 billion for the quarter, compared to the consensus estimate of $60.94 billion. Apple had a net margin of 21.55% and a return on equity of 39.97%. Apple’s revenue for the quarter was up 15.6% on a year-over-year basis. During the same period last year, the company posted $2.10 EPS. analysts forecast that Apple will post 11.43 EPS for the current fiscal year.Want to see what other hedge funds are holding AAPL? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for Apple (NASDAQ:AAPL). Apple Apple ', 'NEW YORK InvestorsObserver issues critical PriceWatch Alerts for AAPL, BPMX, CCCL, NFLX, and WFT.AAPL: https://www.investorsobserver.com/pr-stocks-lp/?stocksymbol=AAPL&prnumber=010220190 BPMX: https://www.investorsobserver.com/pr-stocks-lp/?stocksymbol=BPMX&prnumber=010220190 CCCL: https://www.investorsobserver.com/pr-stocks-lp/?stocksymbol=CCCL&prnumber=010220190 NFLX: https://www.investorsobserver.com/pr-stocks-lp/?stocksymbol=NFLX&prnumber=010220190 WFT: https://www.investorsobserver.com/pr-stocks-lp/?stocksymbol=WFT&prnumber=010220190 (Note: You may have to copy this link into your browser then press the [ENTER] key.)', 'CHICAGO , April 13, 2018 /PRNewswire/ -- InvestorsObserver issues critical PriceWatch Alerts for AAPL, AMD, BAC, GPRO, and WMT.AAPL :  Click Here to get a report on Apple AMD :  Click Here to get a report on Advanced Micro Devices BAC :  Click Here to get a report on Bank of America GPRO :  Click Here to get a report on GoPro WMT :  Click Here to get a report on Wal Mart Or get a report on any stock symbol here ']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 17276/17276 [00:28<00:00, 605.44it/s]\n",
            "100%|██████████| 4319/4319 [00:07<00:00, 606.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI4pOeNs7kqK",
        "outputId": "ab0f0e6a-6749-472b-c5b0-8669f41e2f9d"
      },
      "source": [
        "test_data = pd.read_csv('Apple60_Major.csv', sep=',', header=0)\n",
        "\n",
        "test_corpus = test_data['News'].tolist()\n",
        "\n",
        "processed_test_sample = []\n",
        "for doc in tqdm(test_corpus):\n",
        "  tokens = word_tokenize(doc)\n",
        "  filtered = [word for word in tokens if word not in stop_words]\n",
        "  processed_test_sample.append(\" \".join(filtered))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 711/711 [00:00<00:00, 1169.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htG1PhCgAhzs",
        "outputId": "86ada4d3-a61c-45ed-a257-69c2a36410ea"
      },
      "source": [
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(raw_docs_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpUfiGO1AeB9",
        "outputId": "a8d287a6-c9dc-4f2a-951d-1731e9b05255"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(processed_docs_train + processed_docs_test)  \n",
        "\n",
        "vocab_length = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(vocab_length)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6bTPyVFDPxh",
        "outputId": "e41c497f-d52e-42f8-e989-0190562da783"
      },
      "source": [
        "MAX_NB_WORDS = vocab_length\n",
        "max_seq_len = 1000\n",
        "\n",
        "word_seq_train = tokenizer.texts_to_sequences(processed_docs_train)\n",
        "word_seq_test = tokenizer.texts_to_sequences(processed_docs_test)\n",
        "word_seq_testsample = tokenizer.texts_to_sequences(processed_test_sample)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "word_seq_train = pad_sequences(word_seq_train, maxlen=max_seq_len)\n",
        "word_seq_test = pad_sequences(word_seq_test, maxlen=max_seq_len)\n",
        "word_seq_testsample = pad_sequences(word_seq_testsample, maxlen=max_seq_len)\n",
        "\n",
        "print(len(word_index))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qzxfGCAcZHT",
        "outputId": "05c0521d-ab72-4995-d2b5-e156f14e1e16"
      },
      "source": [
        "import requests, zipfile, io\n",
        "zip_file_url = \"https://nlp.stanford.edu/data/glove.twitter.27B.zip\"\n",
        "r = requests.get(zip_file_url)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "\n",
        "print(\"GloVE available locally\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GloVE available locally\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBKql0OIg5eW",
        "outputId": "7513cec2-b99b-4b8f-a833-620faa49eea6"
      },
      "source": [
        "import codecs\n",
        "\n",
        "embeddings_index = {}\n",
        "#f = codecs.open(‘crawl-300d-2M.vec’, encoding=’utf-8')\n",
        "# for Glove\n",
        "f = codecs.open('glove.6B.100d.txt', encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "  values = line.rstrip().rsplit(' ')\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000it [00:17, 22650.18it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esSJoZRNOeNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ccc252-cc39-442f-d60a-3a372a769621"
      },
      "source": [
        "words_not_found = []\n",
        "embed_dim = 100\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index)+1)\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i >= nb_words:\n",
        "     continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  \n",
        "  if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "     embedding_matrix[i] = embedding_vector\n",
        "  else:\n",
        "     words_not_found.append(word)\n",
        "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of null word embeddings: 13310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIKBjnkIO1R9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a936273-705d-45d9-8e3b-dea71cebf4b7"
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Embedding, Bidirectional, Dense, Dropout, LSTM, Flatten, Conv1D, MaxPooling1D, Activation\n",
        "from keras.initializers import Constant\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Embedding(nb_words, embed_dim, input_length=max_seq_len, weights=[embedding_matrix],trainable=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 1000, 100)         4595200   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1000, 100)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 996, 64)           32064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 249, 64)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               66000     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 4,693,365\n",
            "Trainable params: 98,165\n",
            "Non-trainable params: 4,595,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbc9vMcO5qm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56599c31-5114-408b-bff1-d141387c0983"
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "labels = to_categorical(np.asarray(train_df['Movement']))\n",
        "y_train = np.array(train_df['Movement'])\n",
        "\n",
        "print(labels[:10])\n",
        "print(y_train[:10])\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n",
            "[0 0 1 0 1 1 1 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPdG5lzNsChK"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3iLcVYWI3Ax",
        "outputId": "e9949b61-4f3f-481a-ceeb-2833a243020e"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model.fit(word_seq_train, y_train, epochs=10, validation_split=0.2)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "432/432 [==============================] - 11s 21ms/step - loss: 0.3424 - accuracy: 0.8306 - f1_m: 0.8226 - precision_m: 0.8273 - recall_m: 0.8289 - val_loss: 1.0614 - val_accuracy: 0.5385 - val_f1_m: 0.5154 - val_precision_m: 0.5295 - val_recall_m: 0.5189\n",
            "Epoch 2/10\n",
            "432/432 [==============================] - 9s 20ms/step - loss: 0.3254 - accuracy: 0.8486 - f1_m: 0.8426 - precision_m: 0.8441 - recall_m: 0.8494 - val_loss: 1.0792 - val_accuracy: 0.5460 - val_f1_m: 0.5303 - val_precision_m: 0.5370 - val_recall_m: 0.5398\n",
            "Epoch 3/10\n",
            "432/432 [==============================] - 9s 20ms/step - loss: 0.3198 - accuracy: 0.8516 - f1_m: 0.8457 - precision_m: 0.8500 - recall_m: 0.8500 - val_loss: 1.1170 - val_accuracy: 0.5373 - val_f1_m: 0.5338 - val_precision_m: 0.5296 - val_recall_m: 0.5554\n",
            "Epoch 4/10\n",
            "432/432 [==============================] - 8s 20ms/step - loss: 0.3192 - accuracy: 0.8450 - f1_m: 0.8379 - precision_m: 0.8436 - recall_m: 0.8409 - val_loss: 1.1434 - val_accuracy: 0.5408 - val_f1_m: 0.4984 - val_precision_m: 0.5408 - val_recall_m: 0.4785\n",
            "Epoch 5/10\n",
            "432/432 [==============================] - 9s 20ms/step - loss: 0.3220 - accuracy: 0.8461 - f1_m: 0.8387 - precision_m: 0.8464 - recall_m: 0.8403 - val_loss: 1.1411 - val_accuracy: 0.5414 - val_f1_m: 0.5109 - val_precision_m: 0.5363 - val_recall_m: 0.5043\n",
            "Epoch 6/10\n",
            "432/432 [==============================] - 9s 20ms/step - loss: 0.3095 - accuracy: 0.8549 - f1_m: 0.8484 - precision_m: 0.8479 - recall_m: 0.8587 - val_loss: 1.1243 - val_accuracy: 0.5367 - val_f1_m: 0.5072 - val_precision_m: 0.5337 - val_recall_m: 0.4995\n",
            "Epoch 7/10\n",
            "432/432 [==============================] - 9s 20ms/step - loss: 0.3127 - accuracy: 0.8531 - f1_m: 0.8455 - precision_m: 0.8523 - recall_m: 0.8486 - val_loss: 1.1429 - val_accuracy: 0.5402 - val_f1_m: 0.5374 - val_precision_m: 0.5302 - val_recall_m: 0.5633\n",
            "Epoch 8/10\n",
            "432/432 [==============================] - 9s 20ms/step - loss: 0.2883 - accuracy: 0.8632 - f1_m: 0.8574 - precision_m: 0.8582 - recall_m: 0.8658 - val_loss: 1.1609 - val_accuracy: 0.5396 - val_f1_m: 0.5240 - val_precision_m: 0.5335 - val_recall_m: 0.5325\n",
            "Epoch 9/10\n",
            "432/432 [==============================] - 9s 20ms/step - loss: 0.2991 - accuracy: 0.8582 - f1_m: 0.8515 - precision_m: 0.8552 - recall_m: 0.8552 - val_loss: 1.1898 - val_accuracy: 0.5385 - val_f1_m: 0.5145 - val_precision_m: 0.5340 - val_recall_m: 0.5158\n",
            "Epoch 10/10\n",
            "432/432 [==============================] - 9s 20ms/step - loss: 0.2985 - accuracy: 0.8628 - f1_m: 0.8560 - precision_m: 0.8547 - recall_m: 0.8660 - val_loss: 1.1885 - val_accuracy: 0.5480 - val_f1_m: 0.5382 - val_precision_m: 0.5400 - val_recall_m: 0.5537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrzOz3a9HEOE",
        "outputId": "a9bf8d95-a815-49e2-d54c-b638de5b149d"
      },
      "source": [
        "y_test1 = np.array(test_df['Movement'])\n",
        "y_test2 = to_categorical(np.asarray(test_df['Movement']))\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate(word_seq_test, y_test1, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))\n",
        "print('loss: %f' % (loss*100))\n",
        "print('f1: %f' % (f1_score))\n",
        "print('precision: %f' % (precision))\n",
        "print('recall: %f' % (recall))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 55.753648\n",
            "loss: 113.778436\n",
            "f1: 0.557031\n",
            "precision: 0.549021\n",
            "recall: 0.577063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO_GbloIf2IH",
        "outputId": "9a021075-222b-4ff0-c78b-b59d52df2f5d"
      },
      "source": [
        "test_data[\"Movement\"].replace({-1: 0}, inplace=True)\n",
        "y_testsample = np.array(test_data['Movement'])\n",
        "probas = model.predict(word_seq_testsample)\n",
        "predict_labels = (probas < 0.5).astype(np.int)\n",
        "\n",
        "print(predict_labels)\n",
        "np.savetxt(\"foo.csv\", predict_labels, delimiter=\",\")\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate(word_seq_testsample, y_testsample, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))\n",
        "print('loss: %f' % (loss*100))\n",
        "print('f1: %f' % (f1_score))\n",
        "print('precision: %f' % (precision))\n",
        "print('recall: %f' % (recall))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]]\n",
            "Accuracy: 67.651194\n",
            "loss: 82.515490\n",
            "f1: 0.589556\n",
            "precision: 0.623530\n",
            "recall: 0.610917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnCUiSNRlpJ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}